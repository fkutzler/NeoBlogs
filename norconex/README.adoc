= Importing data from the web with Norconex & Neo4j


image::committer-neo4j.png[]

== Introduction

Neo4j provides many tools for importing data, they're known as LOAD CSV from Cypher queries, but also the neo4j-admin import tool. It is also possible to import data from many other systems like Elastic Search, SQL databases, MongoDB, CouchBase using APOC procedures plugin. Finally, ETL tools like Kettle provides features aimed to reduce the data transformation effort. In short hand, the data manipulation ecosystem around Neo4j is very complete. 

And to achieve this ecosystem, now comes the time to import in Neo4J data directly from the Web. To do that, we need to use an external tool called Web Crawler (also known as Web Spider or Web Scraper).

== What is a Web Crawler ?

It's a program, a robot, specialized in browsing the Web, deeper and deeper. Its operation is pretty simple.

Consider the following cycle of work:

* download a Web page
* extract the links from this page to other pages and add them to the _frontier_ (a pool of URLs)
* extract content and meta-data of this page and store them somewhere

image::crawler_principle.png[crawler,300,200]

== Caution: politness rules

The basic principle of crawling looks like simple thing to do and it's true. However, you have to pay attention to respect politness rules. It is very important to understand that. We don't want _attack_ a web site, we want just to grab useful data.

* Give a _think time_, a time delay between two downloads, to let the target host breathing. Also avoid to download a site with more two threads
* Respect site rules like ROBOTS.TXT files or No-follow directives
* Be careful about personal data, avoid to donwload them

If you don't do that, you will incur the risk to be blacklisted or to fall down the remote server, and if we need their data, it's clearly not something we want to do.

== Norconex Web Crawler

Norconex is a small IT company from Gatineau (Quebec) specialized in the enterprise search. Norconex also propose a very nice open source Web Crawler kown as _HTTP Collector_. But, Norconex crawler is, before that, a generic pluggable crawl engine and we can see its structure on the image below.  

image::crawler_norconex.png[crawler,600,200]

Many collectors are provided by Norconex (Http, FileSystem, etc.) and many connectors where inject the data, called _committers_ (SQL, Elastic Search, Solr, etc.) are also proposed. 

From a simple XML configuration, you can connect an input (a data collector) to an output (a committer), applying filters or doing some transformations between them.

The last born of these committers is the _Neo4j committer_.

== Meet the California grapes

I live in Burgundy, France and I tasted many wines from this region (and others from other regions in France). Here, the main grapes are the Pinot Noir for red wines and Chardonnay for white wines. Many European grape varietals was imported from Europe to United States before the Phyllox√©ra damages on the old continent. Later, the french grapes was saved by greffons on american foot vines (XIX century).
This is a very interesting story and a strong wine history between our respective countries.

But, I don't know anything about american wines. After reading an article about them, it seems I should starting my initiation by California wines (around 90% of the american production).

Ok, let's go to meet the californian grapes...

== Norconex considerations

A crawl is based on an XML configuration. 
Consider the following points:

* Metadata are the information placed in the `<head/>` section of the HTML page + some information added by Norconex engine (as `collector.rerenced-urls` where are stores all the links available on this page). Use them as key/value pairs.
* Content is the main content placed in `<body/>` section of the HTML page

You can see the flow of the HttpCollector here: link:ex-url.adoc[https://www.norconex.com/collectors/collector-http/flow]

== Finding sources

After some searches on Internet, I found a very good start point: link:ex-url.adoc[https://discovercaliforniawines.com/]
It contains some data about regions, sub-regions, wineries and grapes. I want to build a graph with them to know the repartition of each grape varietal per region or sub-region.

After site analysis, I decide to split my work in two crawls:

* importing varietals first (one XML configuration)
* importing regions, sub-regions and wineries then (one other XML configuration)

Later, I could _wash_ the data to eliminate _noise Nodes_ (unwanted nodes or relationships).

== Import grape varietals

image::varietals.png[varietals]

=== Starting with sources (start Urls)

After inspecting source code of this page: link:ex-url.adoc[https://discovercaliforniawines.com/wine-map-winery-directory/], I can see all grapes (with Ids and values) in the search selector.

I'm beginning the configuration by specifying my starting Urls:

```
...
<startURLs stayOnDomain="true" stayOnPort="true" stayOnProtocol="true">  
      <url>https://discovercaliforniawines.com/wine-map-winery-directory/</url>                         
</startURLs>
...
```

=== Making one document to many

Norconex is able to split one page two many, based on CSS selector. Furthermore, I can split each option on this `<select/>` tag:

```
...
 <importer>
        <preParseHandlers>          
          <splitter class="com.norconex.importer.handler.splitter.impl.DOMSplitter"
            selector="#varietal_select option"
            parser="html"/>
...
```

The _importer_ phase is reached when the document (the Web page) pass filters, then the document treatment process begins. Here, the `DOMSplitter` component makes one document (imported as new document) for each tag mathcing the CSS selector `#varietal_select option`.

=== Adding _value_ and _id_ 

Each new document  content built by the `DOMSplitter` looks like:

```
<option class="text-dark" id="1554">Cabernet Sauvignon<option>
```

It will be very interesting to extract _value_ (text) and _id_ to put them in the metadata. As we will see later, the varietal could be linked to wineries with this identifier.

Norconex provides a component to extract data from CSS Selector, the `DOMTagger`:

```
...
        
          <tagger class="com.norconex.importer.handler.tagger.impl.DOMTagger">
              <dom selector="option"  toField="varietal_id"   extract="attr(value)"/>
              <dom selector="option"  toField="varietal"   extract="ownText"/>             
          </tagger>
...
```

=== Stamping these pages with Varietal type

To provides more qualified information  when the document will be stored to Neo4j (see later _additionnal labels_), we're going to add a constant on each page imported from the document splitter.

Norconex provides a `ConstantTagger` to add a explicit value to a matadata fieldn here the field is _TYPE_:

```
...        
          <tagger class="com.norconex.importer.handler.tagger.impl.ConstantTagger"
              onConflict="replace" >      
            <restrictTo caseSensitive="false" field="document.embedded.reference">
               #varietal_select.*
            </restrictTo>
            <constant name="TYPE">VARIETAL</constant>
          </tagger>
           
      <preParseHandlers>
   <importer>
...
```

The `restrictTo` element allows to specify a regular expression to filter the documents tagged.

=== Storing in Neo4j

This is the goal: storing data in Neo4j.

First of all, choose the right Norconex committer: `com.norconex.committer.neo4j.Neo4jCommitter`
This committer must be configured with the following information:

* The Neo4j connection information
* The node topology (SPLITTED, ONE_NODE, NO_CONTENT)
* the primary label
* the additional labels (optional): 
* the relationships definitions (optional)

Other configuration are mostly common for all the Norconex committers.

```
...
	<committer class="com.norconex.committer.neo4j.Neo4jCommitter">
		<uri>bolt://localhost:7687</uri>
		<user>neo4j</user>
		<password>neo4j</password>
		<authentType>BASIC</authentType>      

		<nodeTopology>NO_CONTENT</nodeTopology>
		<primaryLabel>CALIFORNIA</primaryLabel>

		<additionalLabels>
			<sourceField keep="true">TYPE</sourceField>
		</additionalLabels>   

		<sourceReferenceField keep="true">document.reference</sourceReferenceField>
		<targetReferenceField>identity</targetReferenceField>

		<queueSize>5</queueSize>
	</committer>
...
```

==== Node Topology

The node topology defines how a Web page must be stored in Neo4j.

* ONE_NODE: the page will be stored in one node wich contains metadata and content
* NO_CONTENT: the page will be stored in one node wich contains only metadata
* SPLITTED: the page will be stored in three nodes, one super node linked to another one wich contains metadata and linked to another one wich contains content

In my case, I'm not very interested by the content, I want only know how entities are linked. I chose the `NO_CONTENT` topology.


==== Primary label

All nodes imported by this crawl will be stamped as label by this litteral value. Then it is easy to delete or search only on them.

==== Additional labels

They're used to qualify the nodes more precisely. Here we need to parameter a metadata field. The value of this key will be converted into label on the node.

A constant, named _TYPE_ was configured with the `ConstantTagger`, and this is this value I want to add to new nodes. 

=== Starting Norconex and check the result

Now my configuration is completed, I can launch the Web crawler:

```
$> sh collector-http -a start -c confs/california-varietals.xml
```

* _-a_: the action, start or stop
* _-c_: the config file path

When it finished, then I can check the imported data:
```
MATCH (v:VARIETAL) RETURN v.varietal, v.varietal_id
```

And the query produces the following result:

|===
|n.varietal |n.varietal_id |n.varietal |n.varietal_id |n.varietal |n.varietal_id |n.varietal |n.varietal_id

|All Varietals
|null
|Barbera
|1556
|Cabernet Franc
|1555
|Cabernet Sauvignon
|1554 

|Chardonnay
|1529
|Chenin Blanc
|1539
|Dessert wines
|1540
|Gew√ºrztraminer
|1538 

|Grenache Blanc
|1537
|Grenache
|1553
|Malbec
|1552
|Marsanne
|1528

|Merlot
|1551
|Mourv√®dre
|1550
|Muscat/Moscato
|1536 
|Petite Sirah
|1549

|Pinot Blanc
|1535 
|Pinot Gris
|1527
|Pinot Noir
|1548
|Red Blends
|1547

|Riesling
|1534
|Ros√©
|1542
|Roussanne
|1533
|Sangiovese
|1545

|Sauvignon Blanc
|1532
|Semillon
|1526
|Sparkling
|1541
|Syrah
|1544

|Tempranillo
|1546 
|Viognier
|1531
|White Blends
|1530
|Zinfandel
|1543
|===

As we can see, there's unwanted data: _All Varietals_ due to first value in the varietal selector from the web page.
More generally, we can clean these data and delete all nodes where `varietal_id` is null:

```
MATCH (v:VARIETAL) WHERE v.varietal_id IS NULL DELETE v
```

== Import regions and sub-regions

image::regions.png[regions]


=== Start Url and link extractor

Now I want to import California regions and their sub-regions. In the `https://discovercaliforniawines.com/discover-california/` page of this Web site, there's a sub-banner with links to all the regions. And on each page of these regions, there are the links to sub-regions. Nice.

My start Url will be `https://discovercaliforniawines.com/discover-california/` but on this page, I don't want to extract all links from this page, because there is many thing useless in my use case (events, media, etc.).

So, it is necessary to only extract the links from the sub-banner (css selection `#page-menu-bar`), by doing that will also reduce the treatment time.

Norconex allows us to modify the default behavious of its link extractor like this: 

```
...
	<linkExtractors>
		<extractor class="com.norconex.collector.http.url.impl.GenericLinkExtractor">
			<extractSelector>#page-menu-bar</extractSelector>   
			
		</extractor>
	</linkExtractors>
...
```
Note: There are many other parameters for the `GenericLinkExtractor` and other usages too.


=== Reference and document filters

Some words about filters, the _reference filters_ are based on the extracted links, wether or not we put them to the frontier. _document filters_ are triggered when the document is downloaded, filtering based on its meta-data or content.

Our filters are using the Norconex `RegexReferenceFilter`, a filter based on the reference of the document or its link: 

```
...
	<filter class="com.norconex.collector.core.filter.impl.RegexReferenceFilter" onMatch="include">
      		https://discovercaliforniawines.com/discover-california/.*
        </filter>
...
```

=== Constant TYPE for additional labels

As previously, we need to qualify our new nodes more precisely:

```
...
	<tagger class="com.norconex.importer.handler.tagger.impl.ConstantTagger"
              onConflict="noop" >      
            <restrictTo caseSensitive="false" field="document.reference">
                https://discovercaliforniawines.com/discover-california/[\w-?]*/?{0,0}
            </restrictTo>
            <constant name="TYPE">CALIFORNIA_REGION</constant>
        </tagger>
        <tagger class="com.norconex.importer.handler.tagger.impl.ConstantTagger"
              onConflict="noop" >      
            <restrictTo caseSensitive="false" field="document.reference">
                https://discovercaliforniawines.com/discover-california/[\w-?]*/.*
            </restrictTo>
            <constant name="TYPE">CALIFORNIA_SUB_REGION</constant>
        </tagger>
...
```

=== Neo4j committer: creating the relationships

It is probably the most difficult part of a configuration, also the most interesting, because the relationships bring a strong sense to the graph.

First of all, we want to link regions to their sub regions. A region _HAS_ a sub region. Each time we parse a _CALIFORNIA__REGION_ tagged document, we want to create a relationship to a _CALIFORNIA__SUB__REGION_ with the type _HAS__SUB__REGION_

Take a look at the following configuration:

```
	<relationships>
		<relationship type="HAS_SUB_REGION" direction="OUTGOING" targetFindSyntax="MERGE" regexFilter="https://discovercaliforniawines.com/discover-california/[\\w-?]+/.+">

			<sourcePropertyKey label="CALIFORNIA_REGION">collector.referenced-urls</sourcePropertyKey>
		 	<targetPropertyKey label="CALIFORNIA_SUB_REGION">identity</targetPropertyKey>
		</relationship>
	</relationships>
```

* the _type_ attribute gives the name of the Neo4j's relationship.
* the _direction_ attribute its sense.
* the _targetFindSyntax_ gives the way of how the CYPHER query behind these parameters must be created. With `MATCH`, if the targetted node doesn't exist, then the relationship is not created; with `MERGE`, if the targetted node doesn't exist, it will be.
* the _regexFilter_ attribute allows to apply the relationship only on the pages where the source property value (see below) matches the regex. It will avoid bad nodes to be linked. 

The following elements are :

* _sourcePropertyKey_: to define constraints for  building relationship from the current committed page
* _targetPropertyKey_: to define the concerned nodes should be linked

_label_ attribute is an  optional constraint, with these ones each node source or target (or both) must have the requisite label.

And finally, the value inside the element will be evaluated from a meta-data property (for source) and node property (for target).
If the source value is multi-valued (like `collector.referenced-urls`) then one relationship could be created for each value.

To summaries, each url in the source meta-data property `collector.referenced-urls` wich matches with the regex filter is going to create a relationship with a target wich have a property `identity` (default _id_ if no other specified, containing the `document.reference`, the page url) where the matching occurs. If not, the target node is created (`targetFindSyntax="MERGE"`) with the provided identity and the label specified as constraint in the target node. This targetted node will be completed later when the crawler will reach the concerned pages. 


== Linking sub-regions with grape varietals through wineries

There is no way to link sub-regions to varietals directly. On this web site, varietals are only referenced by wineries. So, I have to link sub regions with wineries first and then linking wineries to varietals.

=== Importing wineries

image::wineries.png[regions]


Importing wineries is not so easy, because there are redirections between sub-region pages to wineries pages, for example the link
`https://discovercaliforniawines.com/wineries/acorn-wineryalegria-vineyards-2/` from the sub-region page is redirected to `https://discovercaliforniawines.com/wine-map-winery-directory/#winery=1393050&search=ACORN%20Winery%2FAlegr%C3%ADa%20Vineyards`.
To handle that and having a continuous linkage between these pages, I need to link them. 

First, tagging nodes for TYPE:
```
<tagger class="com.norconex.importer.handler.tagger.impl.ConstantTagger"
            onConflict="noop" >      
   <restrictTo caseSensitive="false" field="document.reference">
      https://discovercaliforniawines.com/wineries/.*
   </restrictTo>
   <constant name="TYPE">WINERY_REDIRECTION</constant>
</tagger>
          
<tagger class="com.norconex.importer.handler.tagger.impl.ConstantTagger"
            onConflict="noop" >      
    <restrictTo caseSensitive="false" field="document.reference">
       https://discovercaliforniawines.com/wine-map-winery-directory/.+
    </restrictTo>
    <constant name="TYPE">WINERY</constant>
 </tagger>
```

Then, I'm going these kind of nodes via the property `redirect-trail` on the targetted page meta-data (injected by Norconex) wich allows to do that:
```
<relationship type="REDIRECT_TO" direction="INCOMING" targetFindSyntax="MATCH">         
   <sourcePropertyKey label="WINERY">collector.redirect-trail</sourcePropertyKey>
   <targetPropertyKey label="WINERY_REDIRECTION">identity</targetPropertyKey>
</relationship> 
```

This configuration leads to create link between these nodes like: `(wineryUrlFromSubregion)-[:REDIRECTED_TO]-(wineryLink)`

=== Linking sub-regions

Now, it's pretty simple. But because there's no way to link the *CALIFORNIA_SUB_REGION* nodes to *WINERY* nodes, I have to link the *CALIFORNIA_SUB_REGION* to *WINERY_REDIRECTION* nodes.

```
<relationship type="HAS_WINERY" direction="OUTGOING" targetFindSyntax="MERGE" regexFilter="https://discovercaliforniawines.com/wineries/.+">         
   <sourcePropertyKey label="CALIFORNIA_SUB_REGION">collector.referenced-urls</sourcePropertyKey>
   <targetPropertyKey label="WINERY_REDIRECTION">identity</targetPropertyKey>
</relationship>
```

Note: Far North California region has no sub-region, in order to let this article readable, the relationship configuration is not showed here but available in the full configuration (see below: external resources).

=== Linking varietals

image::wineries_varietals.png[regions]

Handling varietals links brings a bit of complexity. To link a winery to matched varietals, I have to extract varietals Ids from data present in the page `https://discovercaliforniawines.com/wine-map-winery-directory/`.
The winery selector holds many data like _varietals-id_. 
With a script, I have to extract these varietals Ids and put it in winery meta-data, with a new field called _varietals_:
```
<tagger class="com.norconex.importer.handler.tagger.impl.ScriptTagger">
             <restrictTo caseSensitive="false" field="document.reference">
             https://discovercaliforniawines.com/wine-map-winery-directory/.+
            </restrictTo>
            <script><![CDATA[
	        // extract winery id from Url
                var wineId =  reference.substring(
                    reference.indexOf("=") + 1, 
                    reference.lastIndexOf("&")
                );
                metadata.addString('winery-id', wineId);
                
                // transform text content to Html DOM
                var jsoup = org.jsoup.Jsoup.parse(content);
		// retrieve element relative to current winery
                var elems = jsoup.getElementsByAttributeValue("data-id", wineId);
                var elem = elems.first();
                if (elem != null){
		  // extract data-varietals and transform array [] to | value separator
                  var varietals = elem.parent().attr("data-varietals");
                  varietals= varietals.replace("[","");
                  varietals= varietals.replace("]","");                 
                  var parts = varietals.split (","); 
                  for (i = 0 ; i < parts.length ; i++){
                    metadata.addString('varietals', parts[i]);
                  }                  
                }
                else metadata.addString('varietals', 'none'); 
      
            ]]></script>
</tagger>       
```
Now, I'm able to create the relationships from a winery to related varietals:
```
<relationship type="FROM_WINERY" direction="INCOMING" targetFindSyntax="MATCH">         
   <sourcePropertyKey label="WINERY">varietals</sourcePropertyKey>
   <targetPropertyKey label="VARIETAL">varietal_id</targetPropertyKey>
</relationship>
```
Et voil√† !

Note: labels filters on _sourcePropertyKey_ and _targetPropertyKey_ elements are not mandatory (because implicit in the graph). But, it's an easy way here to doucment the relationship.

== Cleaning the graph

image::full.png[]


Nice, I have a graph but this graph seems like a crawl graph, not a business graph. I want to say, we have many nodes created as the Norconex web crawler download pages.
In fact, I don't need the *WINERY_REDIRECTION* nodes. Well, I'm going to clean my graph by removing them and directly build relationships between sub-regions and wineries with the following query:
```
MATCH (n)-[:HAS_WINERY]->(wr:WINERY_REDIRECTION)-[:REDIRECT_TO]->(w:WINERY) 
DETACH DELETE wr 
MERGE (n)-[:HAS_WINERY]->(w)
```


== Querying the graph

Well, I can now query the graph. First, I would to know how are related regions and sub-regions:

```
MATCH (r:CALIFORNIA_REGION)
OPTIONAL MATCH (r)-[:HAS_SUB_REGION]->(sr:CALIFORNIA_SUB_REGION) 
RETURN r.value AS Region, COLLECT(sr.value) AS Subregions
```

|===
|Region |Subregions 

|"North Coast" 
|["Solano County", "Napa Valley", "Lake County", "Los Carneros", "Mendocino County", "Sonoma County"]

|"Central Coast" 
|["Monterey County", "Santa Barbara County", "San Luis Obispo County", "San Benito County", "Livermore Valley", "Paso Robles", "San Francisco Bay", "Santa Clara Valley", "Santa Cruz Mountains"]

|"Far North California" 
|[]

|"Inland Valleys" 
|["Lodi and the Delta", "Sacramento Valley", "San Joaquin Valley", "Madera County"]

|"Southern California" 
|["Los Angeles Area", "Cucamonga Valley", "Temecula Valley", "San Diego County"]

|"Sierra Foothills" 
|["Amador County", "Placer County", "Yuba County", "Nevada County", "Calaveras County", "El Dorado County"]
|===

Now, I would to know what regions has the high number of wineries: 

```
MATCH (r:CALIFORNIA_SUB_REGION)-[:HAS_WINERY]->(w:WINERY)
RETURN r.value AS SubRegion, count(w) AS WineriesCount 
ORDER BY WineriesCount DESC
```

|===
|Region |SubRegion |WineriesCount 

|"North Coast"
|"Napa Valley"	
|128

|"North Coast"
|"Sonoma County"
|110

|"Central Coast"
|"Paso Robles"	
|43

|"Central Coast"
|"Santa Barbara County"	
|41

|"Central Coast"
|"San Luis Obispo County"	
|26

|...
|...
|...
|===

With no surprise, _Napa Valley_ goes ahead, it was probably the only one american wine region I known to now.

And finally, I would to know what kind of grapes are more cultivated by wineries:

```
MATCH (r:CALIFORNIA_REGION)
MATCH (r)-[:HAS_SUB_REGION]->(sr:CALIFORNIA_SUB_REGION)
MATCH (sr)-[:HAS_WINERY]->(w:WINERY)
MATCH (w)<-[:FROM_WINERY]->(v:VARIETAL)
WITH r,w, v ORDER BY v.value
RETURN v.value AS Varietal,COUNT(w) AS WineriesCount 
ORDER BY WineriesCount DESC
```

|===
|Varietal |WineriesCount 

|"Cabernet Sauvignon"	
|329

|"Chardonnay"	
|316

|"Syrah"	
|228

|"Zinfandel"	
|224

|"Pinot Noir"	
|219

|"Merlot"	
|202

|"Sauvignon Blanc"	
|190

|...
|...
|===

_Cabernet Sauvignon_ is the most cultivated grape in California by 329 wineries (on 598). Red grape variety known worldwide, it has become one of the most widespread grape varieties in the world. It owes its international recognition to the great wines of the vineyards of Bordeaux, France. _Chardonnay_, in second position, is a white grape from the vineyards of Burgundy, France. It is used to make great white wines but also to make sparkling champagne wines.

== Beyond this sample

Using Norconex web crawler in combination
